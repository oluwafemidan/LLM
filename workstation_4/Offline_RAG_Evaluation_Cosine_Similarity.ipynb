{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32b50780-06dd-4b93-af1a-92ef305a954a",
      "metadata": {
        "id": "32b50780-06dd-4b93-af1a-92ef305a954a"
      },
      "source": [
        "# Load ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0af7d85-750f-4d6a-8e89-59a8d5e87dfd",
      "metadata": {
        "id": "b0af7d85-750f-4d6a-8e89-59a8d5e87dfd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('documents-with-ids.json', 'rt') as f_input:\n",
        "    documents = json.load(f_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0160c49-567d-483c-b856-e48f84d71720",
      "metadata": {
        "id": "c0160c49-567d-483c-b856-e48f84d71720",
        "outputId": "889730e2-5452-4462-f97f-b2313cacdc8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
              " 'section': 'General course-related questions',\n",
              " 'question': 'Course - What are the prerequisites for this course?',\n",
              " 'course': 'data-engineering-zoomcamp',\n",
              " 'id': '1f6520ca'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1323b160-cebf-4317-9a96-a4bf12ca019c",
      "metadata": {
        "id": "1323b160-cebf-4317-9a96-a4bf12ca019c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_ground_truth = pd.read_csv(\"ground-truth-data.csv\")\n",
        "df_ground_truth = df_ground_truth[df_ground_truth.course == \"machine-learning-zoomcamp\"]\n",
        "ground_truth = df_ground_truth.to_dict(orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024c097b-46a1-470c-a573-a1d7fee0bbb8",
      "metadata": {
        "id": "024c097b-46a1-470c-a573-a1d7fee0bbb8",
        "outputId": "a7b43fb6-a124-483a-dfe4-a7a04b731a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Are sessions recorded if I miss one?',\n",
              " 'course': 'machine-learning-zoomcamp',\n",
              " 'document': '5170565b'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e674a1a-87e5-459f-a5c8-06a7be4173aa",
      "metadata": {
        "id": "2e674a1a-87e5-459f-a5c8-06a7be4173aa",
        "outputId": "df19b964-94e4-43cc-9867-bad9b0e6c3d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_idx = {d['id']: d for d in documents}\n",
        "doc_idx['5170565b']['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2451ee1-bce3-4e67-bed1-a6750deb2260",
      "metadata": {
        "id": "b2451ee1-bce3-4e67-bed1-a6750deb2260"
      },
      "source": [
        "# Index data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77faadb8-ea14-4b43-83b9-f67f97c70623",
      "metadata": {
        "id": "77faadb8-ea14-4b43-83b9-f67f97c70623",
        "outputId": "564f173f-633e-4500-d7d5-e42a45947f9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
        "model = SentenceTransformer(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa856753-8464-4e65-a4cd-e501d90c6264",
      "metadata": {
        "id": "fa856753-8464-4e65-a4cd-e501d90c6264",
        "outputId": "279d7240-ab2b-4b6b-ddf1-328c1376f598"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course_questions'})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "es_client = Elasticsearch('http://localhost:9200')\n",
        "\n",
        "index_setting = {\n",
        "    \"settings\": {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 0\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"text\": {\"type\": \"text\"},\n",
        "            \"section\": {\"type\": \"text\"},\n",
        "            \"question\": {\"type\": \"text\"},\n",
        "            \"course\": {\"type\": \"keyword\"},\n",
        "            \"id\":{\"type\": \"keyword\"},\n",
        "            \"question_vector\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 384,\n",
        "                \"index\": True,\n",
        "                \"similarity\":\"cosine\"\n",
        "            },\n",
        "            \"text_vector\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 384,\n",
        "                \"index\": True,\n",
        "                \"similarity\":\"cosine\"\n",
        "            },\n",
        "            \"question_text_vector\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 384,\n",
        "                \"index\": True,\n",
        "                \"similarity\":\"cosine\"\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "index_name = \"course_questions\"\n",
        "\n",
        "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
        "es_client.indices.create(index=index_name, body=index_setting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3aa00dc-e2e3-41f1-b44d-0231eab16457",
      "metadata": {
        "id": "b3aa00dc-e2e3-41f1-b44d-0231eab16457",
        "outputId": "14bbf22a-e898-4c67-eae9-d48c5645305f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [01:14<00:00, 12.65it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "for doc in tqdm(documents):\n",
        "    questions = doc['question']\n",
        "    text = doc['text']\n",
        "\n",
        "    doc['question_text_vector'] = model.encode(questions + ' ' + text)\n",
        "\n",
        "    es_client.index(index=index_name, document=doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c60028c2-64d4-4106-a7d0-d495197b59f2",
      "metadata": {
        "id": "c60028c2-64d4-4106-a7d0-d495197b59f2"
      },
      "source": [
        "# Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9867adf-8007-4ff8-bab5-56ecaf63a329",
      "metadata": {
        "id": "d9867adf-8007-4ff8-bab5-56ecaf63a329"
      },
      "outputs": [],
      "source": [
        "def elastic_search_knn(field, vector, course):\n",
        "        knn = {\n",
        "            \"field\" : field,\n",
        "            \"query_vector\": vector,\n",
        "            \"k\" : 5,\n",
        "            \"num_candidates\" : 10000,\n",
        "            \"filter\": {\n",
        "                \"term\": {\n",
        "                    \"course\": course\n",
        "\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "        search_query = {\n",
        "            \"knn\": knn,\n",
        "            \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
        "\n",
        "        }\n",
        "\n",
        "        es_results = es_client.search(\n",
        "            index=index_name,\n",
        "            body=search_query\n",
        "    )\n",
        "\n",
        "        result_docs = []\n",
        "\n",
        "        for hit in es_results[\"hits\"][\"hits\"]:\n",
        "            result_docs.append(hit['_source'])\n",
        "\n",
        "        return result_docs\n",
        "\n",
        "def question_text_vector_knn(q):\n",
        "    question = q['question']\n",
        "    course = q['course']\n",
        "\n",
        "    v_q = model.encode(question)\n",
        "\n",
        "    return elastic_search_knn('question_text_vector', v_q, course)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8282bfd3-b1f0-403b-96b4-603f2eee5e94",
      "metadata": {
        "id": "8282bfd3-b1f0-403b-96b4-603f2eee5e94",
        "outputId": "a1222e7a-ec55-4e73-8690-3b06df0b596f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What if I miss a session?',\n",
              "  'course': 'machine-learning-zoomcamp',\n",
              "  'section': 'General course-related questions',\n",
              "  'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
              "  'id': '5170565b'},\n",
              " {'question': 'The same accuracy on epochs',\n",
              "  'course': 'machine-learning-zoomcamp',\n",
              "  'section': '8. Neural Networks and Deep Learning',\n",
              "  'text': \"Problem description\\nThe accuracy and the loss are both still the same or nearly the same while training.\\nSolution description\\nIn the homework, you should set class_mode='binary' while reading the data.\\nAlso, problem occurs when you choose the wrong optimizer, batch size, or learning rate\\nAdded by Ekaterina Kutovaia\",\n",
              "  'id': '7d11d5ce'},\n",
              " {'question': 'Will I get a certificate if I missed the midterm project?',\n",
              "  'course': 'machine-learning-zoomcamp',\n",
              "  'section': 'General course-related questions',\n",
              "  'text': \"Yes, it's possible. See the previous answer.\",\n",
              "  'id': '1d644223'},\n",
              " {'question': 'Is it going to be live? When?',\n",
              "  'course': 'machine-learning-zoomcamp',\n",
              "  'section': 'General course-related questions',\n",
              "  'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
              "  'id': '39fda9f0'},\n",
              " {'question': 'Useful Resource for Missing Data Treatment\\nhttps://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook',\n",
              "  'course': 'machine-learning-zoomcamp',\n",
              "  'section': '2. Machine Learning for Regression',\n",
              "  'text': '(Hrithik Kumar Advani)',\n",
              "  'id': '81b8e8d0'}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_text_vector_knn(dict(\n",
        "    question = \"Are session recorded if i miss one?\",\n",
        "    course='machine-learning-zoomcamp'\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a4aa602-c4ec-4dca-ac63-9380d21a67ae",
      "metadata": {
        "id": "7a4aa602-c4ec-4dca-ac63-9380d21a67ae"
      },
      "source": [
        "# The RAG flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50c66457-54c3-49eb-a699-bfa6f03e521c",
      "metadata": {
        "id": "50c66457-54c3-49eb-a699-bfa6f03e521c"
      },
      "outputs": [],
      "source": [
        "def build_prompt(query, search_results):\n",
        "    prompt_template = \"\"\"\n",
        "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
        "    use only the facts from the CONTEXT when answering the QUESTION.\n",
        "    If the CONTEXT does not provide sufficient information, politely indicate that the information is not available.\n",
        "    Consider any relevant keywords or phrases in the QUESTION to tailor the answer.\n",
        "\n",
        "\n",
        "    QUESTION: {question}\n",
        "\n",
        "    CONTEXT:\n",
        "    {context}\n",
        "    \"\"\".strip()\n",
        "\n",
        "    context = \"\"\n",
        "\n",
        "    for doc in search_results:\n",
        "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
        "\n",
        "    prompt = prompt_template.format(question=query, context=context).strip()\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b4fa38-4365-4e05-a6ab-c5650d218c96",
      "metadata": {
        "id": "b6b4fa38-4365-4e05-a6ab-c5650d218c96"
      },
      "outputs": [],
      "source": [
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "client = MistralClient()\n",
        "\n",
        "def llm(prompt):\n",
        "    chat_response = client.chat(\n",
        "    model=\"mistral-large-latest\",\n",
        "    messages=[ChatMessage(role=\"user\", content=prompt)]\n",
        "    )\n",
        "\n",
        "    return chat_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4d5cc6-a93d-4377-9954-e09527c50c36",
      "metadata": {
        "id": "ed4d5cc6-a93d-4377-9954-e09527c50c36"
      },
      "outputs": [],
      "source": [
        "def rag(query: dict, model = \"mistral-large-latest\" ) -> str:\n",
        "    search_results = question_text_vector_knn(query)\n",
        "    prompt = build_prompt(query['question'], search_results)\n",
        "    answer = llm(prompt)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de33b969-687a-4102-917b-f522d0f98eb1",
      "metadata": {
        "id": "de33b969-687a-4102-917b-f522d0f98eb1",
        "outputId": "d6cef30a-77bd-49c1-e577-9ddbaf87977f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Are sessions recorded if I miss one?',\n",
              " 'course': 'machine-learning-zoomcamp',\n",
              " 'document': '5170565b'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea76e48-6d38-4562-a310-b246e8c38664",
      "metadata": {
        "id": "3ea76e48-6d38-4562-a310-b246e8c38664",
        "outputId": "36a2881d-f4ce-426d-b7ee-add6c736d374"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, sessions are recorded if you miss one. Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag(ground_truth[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18c0280e-d7a7-42a3-a0ca-6c537c560296",
      "metadata": {
        "id": "18c0280e-d7a7-42a3-a0ca-6c537c560296",
        "outputId": "993eb5de-b2fd-42cd-df01-3b2d78cd7b53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_idx['5170565b']['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79543a54-97ec-4764-98c0-9813c6a808c0",
      "metadata": {
        "id": "79543a54-97ec-4764-98c0-9813c6a808c0"
      },
      "source": [
        "# Cosine similarity metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e373dc-cfb5-40c1-a61b-3c2fb0706ed7",
      "metadata": {
        "id": "d1e373dc-cfb5-40c1-a61b-3c2fb0706ed7",
        "outputId": "8bcf963a-72b7-4257-f73a-7c7d18a53446"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8014881610870361"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_orig = 'Yes, sessions are recorded if you miss one. Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'\n",
        "answer_llm = 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'\n",
        "\n",
        "v_llm = model.encode(answer_llm)\n",
        "v_orig = model.encode(answer_orig)\n",
        "\n",
        "result = float(v_llm.dot(v_orig))\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59632f0-68a2-47c7-9209-44583e1bc7d0",
      "metadata": {
        "id": "a59632f0-68a2-47c7-9209-44583e1bc7d0",
        "outputId": "ee5c830d-c697-4623-b2b1-82dadc8d59d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Where can I sign up for the course?',\n",
              " 'course': 'machine-learning-zoomcamp',\n",
              " 'document': '0227b872'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61b2e09-066a-44be-9b48-b41445688f3f",
      "metadata": {
        "id": "e61b2e09-066a-44be-9b48-b41445688f3f",
        "outputId": "0b3440f5-bb55-4c03-ce48-8bdf59bf77da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1830"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ground_truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd9e49a-e5b5-49a3-b784-110aaa50ba5d",
      "metadata": {
        "scrolled": true,
        "id": "afd9e49a-e5b5-49a3-b784-110aaa50ba5d",
        "outputId": "7e2111a8-d5ff-4033-e7b8-e7eaa89e29ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|███████████████████████████████████████████████████████████████████████████████████████████████▍              | 1588/1830 [2:27:08<22:25,  5.56s/it]\n"
          ]
        },
        {
          "ename": "MistralAPIException",
          "evalue": "Status: 403. Message: {\"message\":\"Inactive subscription or usage limit reached\"}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMistralAPIException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m answers:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m answer_llm \u001b[38;5;241m=\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m doc_id \u001b[38;5;241m=\u001b[39m rec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m original_doc \u001b[38;5;241m=\u001b[39m doc_idx[doc_id]\n",
            "Cell \u001b[0;32mIn[31], line 4\u001b[0m, in \u001b[0;36mrag\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      2\u001b[0m search_results \u001b[38;5;241m=\u001b[39m question_text_vector_knn(query)\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m build_prompt(query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], search_results)\n\u001b[0;32m----> 4\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
            "Cell \u001b[0;32mIn[30], line 6\u001b[0m, in \u001b[0;36mllm\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm\u001b[39m(prompt):\n\u001b[0;32m----> 6\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral-large-latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
            "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/mistralai/client.py:223\u001b[0m, in \u001b[0;36mMistralClient.chat\u001b[0;34m(self, messages, model, tools, temperature, max_tokens, top_p, random_seed, safe_mode, safe_prompt, tool_choice, response_format)\u001b[0m\n\u001b[1;32m    202\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_chat_request(\n\u001b[1;32m    203\u001b[0m     messages,\n\u001b[1;32m    204\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    216\u001b[0m single_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m     request,\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m     check_model_deprecation_headers_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_deprecation_header_callback_factory(model),\n\u001b[1;32m    221\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m single_response:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatCompletionResponse(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MistralException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo response received\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/mistralai/client.py:148\u001b[0m, in \u001b[0;36mMistralClient._request\u001b[0;34m(self, method, json, path, stream, attempt, data, check_model_deprecation_headers_callback, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m check_model_deprecation_headers_callback:\n\u001b[1;32m    147\u001b[0m             check_model_deprecation_headers_callback(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m--> 148\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MistralConnectionException(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/mistralai/client.py:77\u001b[0m, in \u001b[0;36mMistralClient._check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: Response) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response_status_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     json_response: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m json_response:\n",
            "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/mistralai/client.py:62\u001b[0m, in \u001b[0;36mMistralClient._check_response_status_codes\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m     61\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MistralAPIException\u001b[38;5;241m.\u001b[39mfrom_response(\n\u001b[1;32m     63\u001b[0m         response,\n\u001b[1;32m     64\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstream:\n",
            "\u001b[0;31mMistralAPIException\u001b[0m: Status: 403. Message: {\"message\":\"Inactive subscription or usage limit reached\"}"
          ]
        }
      ],
      "source": [
        "answers = {}\n",
        "\n",
        "for i, rec in enumerate(tqdm(ground_truth)):\n",
        "    if i in answers:\n",
        "        continue\n",
        "\n",
        "    answer_llm = rag(rec)\n",
        "    doc_id = rec['document']\n",
        "    original_doc = doc_idx[doc_id]\n",
        "    answer_orig = original_doc['text']\n",
        "\n",
        "    answers[i] = {\n",
        "        'answer_llm' : answer_llm,\n",
        "        'answer_orig' : answer_orig,\n",
        "        'document' : doc_id,\n",
        "        'question' : rec['question'],\n",
        "        'course' : rec['course'],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f946e5ee-0d98-4ab5-88ec-32bf29d26075",
      "metadata": {
        "id": "f946e5ee-0d98-4ab5-88ec-32bf29d26075"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "pool = ThreadPoolExecutor(max_workers=6)\n",
        "\n",
        "def map_progress(pool, seq, f):\n",
        "    results = []\n",
        "\n",
        "    with tdqm(total=len(seq)) as progress:\n",
        "        futures = []\n",
        "\n",
        "        for el in seq:\n",
        "            future = pool.submit(f, el)\n",
        "            future.add_done_callback(lambda p: progress.update())\n",
        "            futures.append(future)\n",
        "\n",
        "        for future in futures:\n",
        "            result = future.result()\n",
        "            result.append(result)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be5a1b1-28eb-4510-a722-42763d3c808d",
      "metadata": {
        "id": "8be5a1b1-28eb-4510-a722-42763d3c808d"
      },
      "outputs": [],
      "source": [
        "def process_record(rec):\n",
        "    model = \"mistral-large-latest\"\n",
        "    answer_llm = rag(rec, model=model)\n",
        "\n",
        "    doc_id = rec['document']\n",
        "    original_doc = doc_idx[doc_id]\n",
        "    answer_orig = original_doc['text']\n",
        "\n",
        "    return {\n",
        "        'answer_llm': answer_llm,\n",
        "        'answer_orig': answer_orig,\n",
        "        'document': doc_id,\n",
        "        'question': rec['question'],\n",
        "        'course': rec['course'],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583e9d2e-a230-4f18-93ee-1bf9b100971f",
      "metadata": {
        "id": "583e9d2e-a230-4f18-93ee-1bf9b100971f"
      },
      "outputs": [],
      "source": [
        "process_record(ground_truth[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1766c524-af36-46e1-9b0e-eae8a3fd14de",
      "metadata": {
        "id": "1766c524-af36-46e1-9b0e-eae8a3fd14de"
      },
      "outputs": [],
      "source": [
        "results_mistral = map_progress(pool, ground_truth, process_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bdfc7fb-3de3-4988-9026-b61babb742c3",
      "metadata": {
        "id": "9bdfc7fb-3de3-4988-9026-b61babb742c3"
      },
      "outputs": [],
      "source": [
        "df_mistral = pd.DataFrame(results_mistral)\n",
        "df_mistral.to_csv('data/results-mistral.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b29cfc-e270-4162-99b3-f5f12dc36f43",
      "metadata": {
        "id": "24b29cfc-e270-4162-99b3-f5f12dc36f43"
      },
      "outputs": [],
      "source": [
        "!head data/result-mistral.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77996cb6-42f4-4909-bae8-3209bc98ace3",
      "metadata": {
        "id": "77996cb6-42f4-4909-bae8-3209bc98ace3"
      },
      "source": [
        "# Cosine similarity\n",
        "```\n",
        "A  -> Q -> A' cosine similarity\n",
        "\n",
        "A  -> Q -> A'\n",
        "\n",
        "cosine(A, A')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79be80a0-1c5a-4c01-ac19-a139bff051d4",
      "metadata": {
        "id": "79be80a0-1c5a-4c01-ac19-a139bff051d4"
      },
      "outputs": [],
      "source": [
        "results_mistral = df_mistral.to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74983ce7-f6b2-4c40-bdf2-accf1b463182",
      "metadata": {
        "id": "74983ce7-f6b2-4c40-bdf2-accf1b463182"
      },
      "outputs": [],
      "source": [
        "results_mistral[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a82c9dd-337c-4257-8ef2-f137d2f61e63",
      "metadata": {
        "id": "4a82c9dd-337c-4257-8ef2-f137d2f61e63"
      },
      "outputs": [],
      "source": [
        "record = results_mistral[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8fe0167-1247-4ea6-9622-cb602d992350",
      "metadata": {
        "id": "e8fe0167-1247-4ea6-9622-cb602d992350"
      },
      "outputs": [],
      "source": [
        "def compute_similarity(record):\n",
        "    answer_orig = record['answer_orig']\n",
        "    answer_llm = record['answer_llm']\n",
        "\n",
        "    v_llm = model.encode(answer_llm)\n",
        "    v_orig = model.encode(answer_orig)\n",
        "\n",
        "    return v_llm.dot(v_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46fc7fa3-a8e0-4692-9013-9faaff8db8b9",
      "metadata": {
        "id": "46fc7fa3-a8e0-4692-9013-9faaff8db8b9"
      },
      "outputs": [],
      "source": [
        "similarity = []\n",
        "\n",
        "for record in tqdm(results_mistral):\n",
        "    sim = compute_similarity(record)\n",
        "    similarity.append(sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9a3f2c-e6e1-4232-9acb-ef87b8750ecc",
      "metadata": {
        "id": "5c9a3f2c-e6e1-4232-9acb-ef87b8750ecc"
      },
      "outputs": [],
      "source": [
        "df_mistral['cosine'] = similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a01bd8-9a5d-46e7-8970-c100d112823e",
      "metadata": {
        "id": "d3a01bd8-9a5d-46e7-8970-c100d112823e"
      },
      "outputs": [],
      "source": [
        "df_mistral['cosine'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2fbb43-8de4-4b52-8825-4adfa6ec74a1",
      "metadata": {
        "id": "8f2fbb43-8de4-4b52-8825-4adfa6ec74a1"
      },
      "outputs": [],
      "source": [
        "df_mistral.iloc[3].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdad5c4a-202f-447c-a6cb-37c9ead2aa56",
      "metadata": {
        "id": "cdad5c4a-202f-447c-a6cb-37c9ead2aa56"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d16cb7-5d17-473b-b6f1-dcd0a6dc4bce",
      "metadata": {
        "id": "74d16cb7-5d17-473b-b6f1-dcd0a6dc4bce"
      },
      "outputs": [],
      "source": [
        "sns.displot(df_mistral['cosine'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9822e2-077f-4601-ae0c-a256ff21f1bb",
      "metadata": {
        "id": "fb9822e2-077f-4601-ae0c-a256ff21f1bb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfe62b6-12c9-4e2a-ae41-29ac4419720c",
      "metadata": {
        "id": "0cfe62b6-12c9-4e2a-ae41-29ac4419720c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9dc81b-0e04-446b-af54-406ef78143fe",
      "metadata": {
        "id": "de9dc81b-0e04-446b-af54-406ef78143fe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}